{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfb5444",
   "metadata": {
    "id": "4290f21d"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import wget\n",
    "from pyspark.ml.feature import Bucketizer,RegexTokenizer,StopWordsRemover,CountVectorizer,IDF\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623a69a3",
   "metadata": {
    "id": "6d37dc26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a90cfc47-50a4-4e32-9223-91af6517b2c0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.7.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.0.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 477ms :: artifacts dl 19ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a90cfc47-50a4-4e32-9223-91af6517b2c0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 14 already retrieved (0kB/10ms)\n",
      "24/11/25 03:03:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#Spark Session creation configured to interact with Kfka and MongoDB\n",
    "spark = SparkSession.builder.appName(\"pyspark-notebook\").\\\n",
    "config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-avro_2.12:3.0.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "config(\"spark.mongodb.input.uri\",\"mongodb://docker_mongo_1:27017/twitter_db.tweets\").\\\n",
    "config(\"spark.mongodb.output.uri\",\"mongodb://docker_mongo_1:27017/twitter_db.tweets\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7209db",
   "metadata": {
    "id": "394f0e2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|1881509818| [0, 0]|    5.0|This came in on t...|01 26, 2014|  AIXZKN4ACSKI|        David Briner|      Woks very good|    1390694400|\n",
      "|1881509818| [1, 1]|    5.0|I had a factory G...| 02 2, 2012|A1L5P841VIO02V|     Jason A. Kramer|Works as well as ...|    1328140800|\n",
      "|1881509818| [2, 2]|    4.0|If you don't have...|02 28, 2012| AB2W04NI4OEAD|          J. Fernald|It's a punch, tha...|    1330387200|\n",
      "|1881509818| [0, 0]|    4.0|This works no bet...| 02 5, 2012|A148SVSWKTJKU6|Jusitn A. Watts \"...|It's a punch with...|    1328400000|\n",
      "|1881509818| [0, 0]|    4.0|I purchased this ...|04 23, 2013| AAAWJ6LW9WMOO|        Material Man|Ok,tool does what...|    1366675200|\n",
      "|1881509818| [0, 0]|    5.0|Needed this tool ...| 11 2, 2012|A2XX2A4OJCDNLZ| RatherLiveInKeyWest|Glock punch tool ...|    1351814400|\n",
      "|1881509818| [0, 0]|    5.0|If u don't have i...|06 10, 2014|A283UOBQRUNM4Q|       Thomas Dragon|          Great tool|    1402358400|\n",
      "|2094869245| [0, 0]|    4.0|This light will n...|08 31, 2013| AWG3H90WVZ0Z1|         Alec Nelson|             Bright!|    1377907200|\n",
      "|2094869245| [0, 1]|    5.0|Light and laser t...|05 27, 2013|A3V52OTJHKIJZX|A. Saenz Jr. \"Bet...|             Be seen|    1369612800|\n",
      "|2094869245| [0, 0]|    5.0|Does everything i...| 11 2, 2013|A3SZBE5F3UQ9EC|   ChasRat \"ChasRat\"|Bicycle rear tail...|    1383350400|\n",
      "|2094869245| [0, 0]|    4.0|Very bright.  I w...| 05 7, 2014|A2HVMUMOKOGCQ9|            G. Inman|          Great lite|    1399420800|\n",
      "|2094869245| [0, 0]|    3.0|It's cheaply made...| 01 7, 2014|A21AJ9GNCM89MK|                Greg|It's worth the pr...|    1389052800|\n",
      "|2094869245| [0, 0]|    5.0|Mine arrived with...|01 14, 2014|A10X9ME6R66JDX|   Hugo M. M. Rabson|For $11, it's a b...|    1389657600|\n",
      "|2094869245| [0, 0]|    4.0|It works great it...|12 20, 2013|A2I7K5OIEXUI6R|Lswieckitay \"Lswi...|               Bulky|    1387497600|\n",
      "|2094869245| [0, 0]|    5.0|I love this light...|09 18, 2013|A2RCMHV3MHEBDP|          Micah Chan|            Love it!|    1379462400|\n",
      "|2094869245| [0, 0]|    5.0|Bit bulky. One bu...|01 16, 2014|A2A26KED39175E|        Pudknocker71|       Bulky but....|    1389830400|\n",
      "|2094869245| [0, 0]|    5.0|it is bright and ...| 12 7, 2013| ANKZUDSZFUMNZ|              ronald|     rear bike light|    1386374400|\n",
      "|2094869245| [0, 0]|    4.0|A mice bright lig...| 11 4, 2013|A2M93OC5AOMMM3|             Vette71|Needed a little m...|    1383523200|\n",
      "|2094869245| [0, 0]|    4.0|Had one ride on t...|11 12, 2013| AO3M0AXLL0AGW|        Vic D \"Cope\"|Good light for th...|    1384214400|\n",
      "|7245456259| [0, 0]|    2.0|So it worked well...|03 28, 2014|A2NFEGCOY2TO1Q|                Adam|resistance was go...|    1395964800|\n",
      "|7245456259| [0, 0]|    5.0|My girlfriend is ...| 09 5, 2013|A16VC5E75E3KT4|              Dan B.|Girlfriend loves ...|    1378339200|\n",
      "|7245456259| [0, 0]|    5.0|I worked out once...| 07 6, 2014| ACH40GDEWZRJS|         Dark Harden|I'm not opposed t...|    1404604800|\n",
      "|7245456259| [0, 1]|    5.0|I bought the purp...|07 13, 2013| AHRQOLXJE4CBV|  JACK LOBO \"ljb926\"|I BOUGHT THE PURP...|    1373673600|\n",
      "|7245456259| [0, 2]|    5.0|Well I have had t...|06 27, 2013|A3AFVG8GJRVFM1|Melchor Orozco-Ma...|good resistance band|    1372291200|\n",
      "|7245456259| [0, 0]|    5.0|Works just as adv...|04 17, 2014|A27M3YPDI1YU5B|            R. Davis|       Great device.|    1397692800|\n",
      "|7245456259| [0, 0]|    5.0|This band works w...| 03 9, 2013|A1YYDO3HZHED58|Ryan Nathaniel White|Great product, ev...|    1362787200|\n",
      "|7245456313| [0, 0]|    5.0|These bands were ...|01 24, 2014|A1CJ6O4N4ZWGGR|Afrikan \"Freedom ...|   Excellent product|    1390521600|\n",
      "|7245456313| [0, 0]|    5.0|If you are creati...|04 12, 2013|A29NO61G1WH74V|        Alan Smithee|        Gym in a bag|    1365724800|\n",
      "|7245456313| [0, 0]|    4.0|I like it but I h...| 07 6, 2014|A2ZWD1RON75HX3|                  Al|          Great set.|    1404604800|\n",
      "|7245456313| [0, 0]|    5.0|Love the wide var...|12 15, 2012|A1XLWJPVB4WEMP|     Amazon Customer|             Love it|    1355529600|\n",
      "|7245456313| [0, 0]|    5.0|You can vary your...|10 19, 2013| AE4LMEMGK2TI8|         Angela Lunn|           Versatile|    1382140800|\n",
      "|7245456313| [0, 1]|    2.0|I have several di...|04 17, 2014|A1A45IW850QZBT|           AnneMarie|  They are too short|    1397692800|\n",
      "|7245456313| [0, 0]|    5.0|the bands are gre...|12 25, 2011|A2AECU5QSJ6UB7|              arnold|               super|    1324771200|\n",
      "|7245456313| [1, 1]|    5.0|I absolutely love...|07 14, 2013|A1FKGHZYT64TYG|           Ashley Y.|       Lovin' these!|    1373760000|\n",
      "|7245456313| [0, 0]|    5.0|My wife and I use...|07 22, 2013|A3V65EQUFDQ1FL|        Austen Hayes|     Excellent bands|    1374451200|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 35 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.json(\"reviews_Sports_and_Outdoors_5.json.gz\").show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8875a6",
   "metadata": {
    "id": "0e7b9b96",
    "outputId": "716381d8-0374-4219-a493-615e0efae504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "296337"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download dataset if not exists and read it as spark dataframe\n",
    "try:\n",
    "    df0 = spark.read.json(\"reviews_Sports_and_Outdoors_5.json.gz\")\n",
    "except Exception as e:\n",
    "    url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz\"\n",
    "    wget.download(url)\n",
    "    df0 = spark.read.json(\"reviews_Sports_and_Outdoors_5.json.gz\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.withColumn(\"text\",concat(col(\"summary\"), lit(\" \"),col(\"reviewText\")))\\\n",
    " .drop(\"helpful\")\\\n",
    " .drop(\"reviewerID\")\\\n",
    " .drop(\"reviewerName\")\\\n",
    " .drop(\"reviewTime\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fd64c2",
   "metadata": {
    "id": "111b66c2",
    "outputId": "a9c28e07-4cfd-418f-b54c-53ee86a7bc36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           overall|\n",
      "+-------+------------------+\n",
      "|  count|            296337|\n",
      "|   mean| 4.393450699710128|\n",
      "| stddev|0.9869053992908551|\n",
      "|    min|               1.0|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe(\"overall\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "558b1f19",
   "metadata": {
    "id": "91bdffd0",
    "outputId": "9927373e-5fef-4870-dbe4-f06362330b5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|overall|label| count|\n",
      "+-------+-----+------+\n",
      "|    2.0|  0.0| 10204|\n",
      "|    5.0|  1.0|188208|\n",
      "|    1.0|  0.0|  9045|\n",
      "|    4.0|  1.0| 64809|\n",
      "+-------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bucketize data and create labels 0 if overall rating is in (1.0,2.0), otherwise 1\n",
    "df1 = df.filter(\"overall !=3\")\n",
    "\n",
    "splits = [-float(\"inf\"), 4.0, float(\"inf\")]\n",
    "\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"overall\", outputCol=\"label\")\n",
    "\n",
    "df2= bucketizer.transform(df1)\n",
    "\n",
    "df2.groupBy(\"overall\",\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d7ad9a",
   "metadata": {
    "id": "0bce2dc6",
    "outputId": "75c6f1e2-9115-40c8-f8e7-911c8d911763"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|19249|\n",
      "|  1.0|25224|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#take sample to create train and test dataset\n",
    "fractions = {1.0 : .1, 0.0 : 1.0}\n",
    "df3 = df2.stat.sampleBy(\"label\", fractions, 36)\n",
    "df3.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60d16ea8",
   "metadata": {
    "id": "d27c2f55"
   },
   "outputs": [],
   "source": [
    "#Split data as 80-20% Train and Test dataset\n",
    "splitSeed = 5043\n",
    "trainingData, testData = df3.randomSplit([0.8, 0.2], splitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7847d6fb",
   "metadata": {
    "id": "09a57ba9"
   },
   "outputs": [],
   "source": [
    "#Tokenize \n",
    "tokenizer = RegexTokenizer(inputCol=\"text\",outputCol=\"reviewTokensUf\",pattern=\"\\\\s+|[,.()\\\"]\")\n",
    "\n",
    "remover = StopWordsRemover(stopWords=StopWordsRemover.loadDefaultStopWords(\"english\"),inputCol=\"reviewTokensUf\",outputCol=\"reviewTokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70a69af",
   "metadata": {
    "id": "074e54d7"
   },
   "outputs": [],
   "source": [
    "#converts word documents to vectors of token counts\n",
    "cv = CountVectorizer(inputCol=\"reviewTokens\",outputCol=\"cv\",vocabSize=296337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e604273",
   "metadata": {
    "id": "8d009b27"
   },
   "outputs": [],
   "source": [
    "#IDF model\n",
    "idf = IDF(inputCol=\"cv\",outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd2c314",
   "metadata": {
    "id": "c753c97c"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=100,regParam=0.02,elasticNetParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32438b65",
   "metadata": {
    "id": "b49b029a"
   },
   "outputs": [],
   "source": [
    "#Creates a pipeline\n",
    "steps =  [tokenizer, remover, cv, idf,lr]\n",
    "pipeline = Pipeline(stages=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b147e1a",
   "metadata": {
    "id": "d8b9c448"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:49:34 WARN DAGScheduler: Broadcasting large task binary with size 1969.4 KiB\n",
      "24/11/24 17:49:39 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/11/24 17:49:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/11/24 17:49:39 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:39 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:40 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:40 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:40 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:40 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:40 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:42 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:42 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:42 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:42 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:42 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:44 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:44 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:44 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:44 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:44 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:44 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:45 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:45 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:45 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:45 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:45 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:47 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:47 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:47 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:47 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:47 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:48 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:48 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:48 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:48 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:48 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:48 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:49 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:49 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:49 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:49 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:49 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:49 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:50 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:50 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:50 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:50 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:50 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:53 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:53 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:53 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:53 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:53 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:54 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:54 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:54 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:54 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:54 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:54 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:55 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:55 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:55 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:55 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:55 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:55 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n",
      "24/11/24 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 1968.6 KiB\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb4d0e97",
   "metadata": {
    "id": "c3ed06a6"
   },
   "outputs": [],
   "source": [
    "#collecting all metrics\n",
    "vocabulary = model.stages[2].vocabulary\n",
    "weights = model.stages[-1].coefficients.toArray()\n",
    "weights = [float(weight) for weight in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff682795",
   "metadata": {
    "id": "b9b8a949"
   },
   "outputs": [],
   "source": [
    "schema = StructType([StructField('word', StringType()),\n",
    "                     StructField('weight', FloatType())\n",
    "                     ])\n",
    "cdf = spark.createDataFrame(zip(vocabulary, weights), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb493133",
   "metadata": {
    "id": "56346b17",
    "outputId": "4ab8aafe-8635-4531-b456-e25a748aa1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     word|    weight|\n",
      "+---------+----------+\n",
      "|    great| 0.5876225|\n",
      "|   thoses|  0.325535|\n",
      "|  perfect|0.32343474|\n",
      "|     easy| 0.2615016|\n",
      "|   highly|0.25427502|\n",
      "|     love|0.23299988|\n",
      "|excellent|0.22146676|\n",
      "|     nice|0.21586789|\n",
      "|     good|0.20862874|\n",
      "|    works|0.20269535|\n",
      "+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cdf.orderBy(desc(\"weight\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c304bc",
   "metadata": {
    "id": "0dd14bb1",
    "outputId": "963a9ba5-59d7-462a-e3e6-32f02593522b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|         word|     weight|\n",
      "+-------------+-----------+\n",
      "|     returned|-0.38842562|\n",
      "|         poor|-0.33077022|\n",
      "|      useless|-0.30299458|\n",
      "|        waste|-0.27846226|\n",
      "|        broke|-0.26966578|\n",
      "|         junk| -0.2493974|\n",
      "|       return|-0.24831308|\n",
      "|disappointing|-0.22999014|\n",
      "|    returning|-0.21706156|\n",
      "| disappointed|-0.21414408|\n",
      "+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.orderBy(\"weight\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a08c6ce1",
   "metadata": {
    "id": "4a35d20a"
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32c5fc1b",
   "metadata": {
    "id": "86682040"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1986.0 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()  \n",
    "areaUnderROC = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b4110e2",
   "metadata": {
    "id": "7d624986",
    "outputId": "4cf3b71f-5198-45e3-be3d-bc570f222c77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:50:02 WARN DAGScheduler: Broadcasting large task binary with size 2003.5 KiB\n",
      "[Stage 141:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|      asin|overall|          reviewText|             summary|unixReviewTime|                text|label|      reviewTokensUf|        reviewTokens|                  cv|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|7245456313|    1.0|I wish I would ha...|Defective - Be Ca...|    1354492800|Defective - Be Ca...|  0.0|[defective, -, be...|[defective, -, ca...|(71899,[0,11,15,1...|(71899,[0,11,15,1...|[1.99668098749155...|[0.88044816229076...|       0.0|\n",
      "|7245456313|    5.0|I bought this ban...|Great product, aw...|    1400112000|Great product, aw...|  1.0|[great, product, ...|[great, product, ...|(71899,[0,1,2,4,5...|(71899,[0,1,2,4,5...|[-3.3010460840681...|[0.03553531986812...|       1.0|\n",
      "|7245456313|    5.0|I used to be a pe...|GREAT product for...|    1304899200|GREAT product for...|  1.0|[great, product, ...|[great, product, ...|(71899,[1,8,16,20...|(71899,[1,8,16,20...|[-1.4400664803236...|[0.19153505391366...|       1.0|\n",
      "|7245456313|    5.0|My arms are burni...|Love Love Love th...|    1358985600|Love Love Love th...|  1.0|[love, love, love...|[love, love, love...|(71899,[6,10,13,3...|(71899,[6,10,13,3...|[-3.2229472289437...|[0.03831125139765...|       1.0|\n",
      "|B00000IURU|    5.0|Use this at pre s...|Toddlers love thi...|    1400803200|Toddlers love thi...|  1.0|[toddlers, love, ...|[toddlers, love, ...|(71899,[4,18,38,3...|(71899,[4,18,38,3...|[-0.6913907181625...|[0.33372377250877...|       1.0|\n",
      "|B00000J6JO|    1.0|As I write this r...|Very Cheaply made...|    1369699200|Very Cheaply made...|  0.0|[very, cheaply, m...|[cheaply, made, p...|(71899,[4,8,14,18...|(71899,[4,8,14,18...|[1.19648991575825...|[0.76789977056535...|       0.0|\n",
      "|B00000J6JO|    4.0|I saw a lot of ne...|Really good gift ...|    1401148800|Really good gift ...|  1.0|[really, good, gi...|[really, good, gi...|(71899,[0,2,3,4,5...|(71899,[0,2,3,4,5...|[-0.4114566537645...|[0.39856289439001...|       1.0|\n",
      "|B0000224UE|    5.0|I was given this ...|   Always by my side|    1361404800|Always by my side...|  1.0|[always, by, my, ...|[always, side, gi...|(71899,[0,4,5,6,1...|(71899,[0,4,5,6,1...|[0.07039114776988...|[0.51759052424810...|       0.0|\n",
      "|B0000224UE|    5.0|The victor inbox ...|Victorinox Multi-...|    1361923200|Victorinox Multi-...|  1.0|[victorinox, mult...|[victorinox, mult...|(71899,[6,14,16,1...|(71899,[6,14,16,1...|[-1.1410191572624...|[0.24213329163981...|       1.0|\n",
      "|B000030056|    1.0|Cheap product!  W...|       Cheap product|    1309564800|Cheap product Che...|  0.0|[cheap, product, ...|[cheap, product, ...|(71899,[4,8,14,17...|(71899,[4,8,14,17...|[1.16342300609824...|[0.76195413639683...|       0.0|\n",
      "|B00003CYPK|    5.0|Trac Ball is just...|One of the best b...|    1226188800|One of the best b...|  1.0|[one, of, the, be...|[one, best, backy...|(71899,[0,3,5,13,...|(71899,[0,3,5,13,...|[-3.1076942546117...|[0.04279098786357...|       1.0|\n",
      "|B00004NKIQ|    5.0|This net is great...|excellent net for...|    1341532800|excellent net for...|  1.0|[excellent, net, ...|[excellent, net, ...|(71899,[6,14,21,2...|(71899,[6,14,21,2...|[-2.1941902835827...|[0.10027341808034...|       1.0|\n",
      "|B00004SQM7|    2.0|This must be more...|          Didn't Fit|    1307404800|Didn't Fit This m...|  0.0|[didn't, fit, thi...|[fit, must, ideal...|(71899,[9,39,41,4...|(71899,[9,39,41,4...|[2.05943139774298...|[0.88689714564144...|       0.0|\n",
      "|B00004SQM9|    1.0|This lock jammed ...|            Not good|    1234656000|Not good This loc...|  0.0|[not, good, this,...|[good, lock, jamm...|(71899,[2,60,113,...|(71899,[2,60,113,...|[0.27827736694021...|[0.56912384699702...|       0.0|\n",
      "|B00004SQM9|    2.0|Works great on fi...|doesn't work well...|    1272326400|doesn't work well...|  0.0|[doesn't, work, w...|[work, well, leve...|(71899,[1,5,6,11,...|(71899,[1,5,6,11,...|[-0.9750220790220...|[0.27388062786154...|       1.0|\n",
      "|B00004SQM9|    4.0|This is a great a...|Works for multipl...|    1369180800|Works for multipl...|  1.0|[works, for, mult...|[works, multiple,...|(71899,[0,1,5,15,...|(71899,[0,1,5,15,...|[-1.4518081953470...|[0.18972343897225...|       1.0|\n",
      "|B00004SQM9|    5.0|I like the combin...|Very good trigger...|    1342051200|Very good trigger...|  1.0|[very, good, trig...|[good, trigger, l...|(71899,[2,3,26,44...|(71899,[2,3,26,44...|[-0.9615364235615...|[0.27657068276025...|       1.0|\n",
      "|B00004T1JW|    5.0|These bases are v...|Very nice set of ...|    1357084800|Very nice set of ...|  1.0|[very, nice, set,...|[nice, set, bases...|(71899,[6,13,15,1...|(71899,[6,13,15,1...|[-1.5148134864671...|[0.18022652998300...|       1.0|\n",
      "|B00004THDC|    4.0|Excellent optics....|    Excellent Optics|    1386288000|Excellent Optics ...|  1.0|[excellent, optic...|[excellent, optic...|(71899,[6,20,22,2...|(71899,[6,20,22,2...|[-2.9582846383312...|[0.04934641382990...|       1.0|\n",
      "|B00004TQ2P|    5.0|Good for kids and...|  Good for my nephew|    1382832000|Good for my nephe...|  1.0|[good, for, my, n...|[good, nephew, go...|(71899,[2,31,47,7...|(71899,[2,31,47,7...|[-0.5040760931475...|[0.37658325100326...|       1.0|\n",
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e28af92f",
   "metadata": {
    "id": "8f3fb74b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:50:06 WARN DAGScheduler: Broadcasting large task binary with size 1983.3 KiB\n",
      "24/11/24 17:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1983.3 KiB\n",
      "24/11/24 17:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1983.3 KiB\n",
      "24/11/24 17:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1983.3 KiB\n",
      "24/11/24 17:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1983.5 KiB\n",
      "24/11/24 17:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1983.5 KiB\n",
      "24/11/24 17:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1983.5 KiB\n",
      "24/11/24 17:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1983.5 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "lp = predictions.select(\"label\", \"prediction\")\n",
    "counttotal = predictions.count()\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(~(col(\"label\") == col(\"prediction\"))).count()\n",
    "ratioWrong = float(wrong) / float(counttotal)\n",
    "lp = predictions.select(  \"prediction\",\"label\")\n",
    "counttotal = float(predictions.count())\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(\"label != prediction\").count()\n",
    "ratioWrong=wrong/counttotal\n",
    "ratioCorrect=correct/counttotal\n",
    "trueneg =( lp.filter(col(\"label\") == 0.0).filter(col(\"label\") == col(\"prediction\")).count()) /counttotal\n",
    "truepos = (lp.filter(col(\"label\") == 1.0).filter(col(\"label\") == col(\"prediction\")).count())/counttotal\n",
    "falseneg = (lp.filter(col(\"label\") == 0.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "falsepos = (lp.filter(col(\"label\") == 1.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "\n",
    "precision= truepos / (truepos + falsepos)\n",
    "recall= truepos / (truepos + falseneg)\n",
    "#fmeasure= 2  precision  recall / (precision + recall)\n",
    "accuracy=(truepos + trueneg) / (truepos + trueneg + falsepos + falseneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7768b32a",
   "metadata": {
    "id": "b7c3824f",
    "outputId": "632ee324-c3f8-4519-f7b0-be3dc85f63e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counttotal   : 9003.0\n",
      "correct      : 7776\n",
      "wrong        : 1227\n",
      "ratioWrong   : 0.13628790403198934\n",
      "ratioCorrect : 0.8637120959680107\n",
      "truen        : 0.3361101854937243\n",
      "truep        : 0.5276019104742864\n",
      "falsen       : 0.08863712095968011\n",
      "falsep       : 0.04765078307230923\n",
      "precision    : 0.9171654759606103\n",
      "recall       : 0.8561643835616438\n",
      "accuracy     : 0.8637120959680107\n"
     ]
    }
   ],
   "source": [
    "print('counttotal   :', counttotal     )\n",
    "print('correct      :', correct        )\n",
    "print('wrong        :', wrong          )\n",
    "print('ratioWrong   :', ratioWrong     )\n",
    "print('ratioCorrect :', ratioCorrect   )\n",
    "print('truen        :', trueneg          )\n",
    "print('truep        :', truepos          )\n",
    "print('falsen       :', falseneg         )\n",
    "print('falsep       :', falsepos         )\n",
    "print('precision    :', precision      )\n",
    "print('recall       :', recall         )\n",
    "#print('fmeasure     :', fmeasure       )\n",
    "print('accuracy     :', accuracy       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01f6d1be",
   "metadata": {
    "id": "ea2f523d",
    "outputId": "c892f587-d3eb-4439-dd16-177052de438e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:50:27 WARN DAGScheduler: Broadcasting large task binary with size 1996.3 KiB\n",
      "[Stage 162:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+\n",
      "|             summary|        reviewTokens|overall|prediction|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "|Buyer Beware - Yo...|[buyer, beware, -...|    2.0|       0.0|\n",
      "|Awful Phone and T...|[awful, phone, te...|    1.0|       0.0|\n",
      "|DO NOT BUY HERE I...|[buy, need, custo...|    1.0|       0.0|\n",
      "|                JUNK|[junk, well, rece...|    1.0|       0.0|\n",
      "|Poor 3-9x40 Hamme...|[poor, 3-9x40, ha...|    1.0|       0.0|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.filter(col(\"prediction\") == 0.0)\\\n",
    ".select(\"summary\",\"reviewTokens\",\"overall\",\"prediction\")\\\n",
    ".orderBy(desc(\"rawPrediction\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84a905f4",
   "metadata": {
    "id": "67f67c23",
    "outputId": "10f5971b-77a4-495c-8207-403a13154f5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:50:31 WARN DAGScheduler: Broadcasting large task binary with size 1996.1 KiB\n",
      "[Stage 163:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+\n",
      "|             summary|        reviewTokens|overall|prediction|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "|My DROID Story an...|[droid, story, co...|    5.0|       1.0|\n",
      "| great trucker phone|[great, trucker, ...|    5.0|       1.0|\n",
      "|    Favorite EDC Bag|[favorite, edc, b...|    4.0|       1.0|\n",
      "|One of My Favorit...|[one, favorites!!...|    4.0|       1.0|\n",
      "|Best Hopper I've ...|[best, hopper, us...|    4.0|       1.0|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.filter(col(\"prediction\")== 1.0)\\\n",
    ".select(\"summary\",\"reviewTokens\",\"overall\",\"prediction\")\\\n",
    ".orderBy(\"rawPrediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1001150",
   "metadata": {
    "id": "46797c12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 17:50:35 WARN TaskSetManager: Stage 168 contains a task of very large size (1385 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/11/24 17:50:35 WARN TaskSetManager: Stage 171 contains a task of very large size (1153 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "dir = \"sentiment/\"\n",
    "model.write().overwrite().save(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77d4a5d0",
   "metadata": {
    "id": "33b356fa"
   },
   "outputs": [],
   "source": [
    "dir = \"sentiment/\"\n",
    "model = PipelineModel.load(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691b206",
   "metadata": {
    "id": "05251f93",
    "outputId": "f1e2ce9d-c8a2-4089-f51e-efb6035c56ba"
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").load()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62b57c",
   "metadata": {
    "id": "fc22ffb8",
    "outputId": "bcfc57d0-d04a-4e88-b453-c00665c792eb"
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").load().select(\"timestamp\",\"text\")\n",
    "splits = [-float(\"inf\"), 0, float(\"inf\")]\n",
    "#bucketizer = Bucketizer(inputCol=\"timestamp_ms\",outputCol=\"sentiment\",splits=splits)\n",
    "\n",
    "#df5= bucketizer.transform(df)\n",
    "predictions = model.transform(df)\n",
    "predictions.select('text','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a902e3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentimentanalyzer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
